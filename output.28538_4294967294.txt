/home/mohammad.bhat/.conda/envs/yolov6_38/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
usage: train.py [-h] [--data-path DATA_PATH] [--conf-file CONF_FILE]
                [--teacher_config TEACHER_CONFIG] [--img-size IMG_SIZE]
                [--rect] [--batch-size BATCH_SIZE] [--epochs EPOCHS]
                [--workers WORKERS] [--device DEVICE]
                [--eval-interval EVAL_INTERVAL] [--eval-final-only]
                [--heavy-eval-range HEAVY_EVAL_RANGE] [--check-images]
                [--check-labels] [--output-dir OUTPUT_DIR] [--name NAME]
                [--dist_url DIST_URL] [--gpu_count GPU_COUNT]
                [--local_rank LOCAL_RANK] [--resume [RESUME]]
                [--write_trainbatch_tb]
                [--stop_aug_last_n_epoch STOP_AUG_LAST_N_EPOCH]
                [--save_ckpt_on_last_n_epoch SAVE_CKPT_ON_LAST_N_EPOCH]
                [--distill] [--distill_feat] [--quant] [--calib]
                [--teacher_model_path TEACHER_MODEL_PATH]
                [--temperature TEMPERATURE] [--fuse_ab]
                [--bs_per_gpu BS_PER_GPU] [--specific-shape] [--height HEIGHT]
                [--width WIDTH]
usage: train.py [-h] [--data-path DATA_PATH] [--conf-file CONF_FILE]
                [--teacher_config TEACHER_CONFIG] [--img-size IMG_SIZE]
                [--rect] [--batch-size BATCH_SIZE] [--epochs EPOCHS]
                [--workers WORKERS] [--device DEVICE]
                [--eval-interval EVAL_INTERVAL] [--eval-final-only]
                [--heavy-eval-range HEAVY_EVAL_RANGE] [--check-images]
                [--check-labels] [--output-dir OUTPUT_DIR] [--name NAME]
                [--dist_url DIST_URL] [--gpu_count GPU_COUNT]
                [--local_rank LOCAL_RANK] [--resume [RESUME]]
                [--write_trainbatch_tb]
                [--stop_aug_last_n_epoch STOP_AUG_LAST_N_EPOCH]
                [--save_ckpt_on_last_n_epoch SAVE_CKPT_ON_LAST_N_EPOCH]
                [--distill] [--distill_feat] [--quant] [--calib]
                [--teacher_model_path TEACHER_MODEL_PATH]
                [--temperature TEMPERATURE] [--fuse_ab]
                [--bs_per_gpu BS_PER_GPU] [--specific-shape] [--height HEIGHT]
                [--width WIDTH]
train.py: error: unrecognized arguments: --local-rank=1
train.py: error: unrecognized arguments: --local-rank=0
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 6749) of binary: /home/mohammad.bhat/.conda/envs/yolov6_38/bin/python
Traceback (most recent call last):
  File "/home/mohammad.bhat/.conda/envs/yolov6_38/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/mohammad.bhat/.conda/envs/yolov6_38/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/mohammad.bhat/.conda/envs/yolov6_38/lib/python3.8/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/home/mohammad.bhat/.conda/envs/yolov6_38/lib/python3.8/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/home/mohammad.bhat/.conda/envs/yolov6_38/lib/python3.8/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/home/mohammad.bhat/.conda/envs/yolov6_38/lib/python3.8/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/mohammad.bhat/.conda/envs/yolov6_38/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/mohammad.bhat/.conda/envs/yolov6_38/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
tools/train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-06-27_16:28:40
  host      : gpu-22
  rank      : 1 (local_rank: 1)
  exitcode  : 2 (pid: 6750)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-06-27_16:28:40
  host      : gpu-22
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 6749)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
